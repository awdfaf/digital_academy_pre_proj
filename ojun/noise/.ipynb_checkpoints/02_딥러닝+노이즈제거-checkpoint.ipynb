{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8914df54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D,Conv1DTranspose,Concatenate,Input\n",
    "import numpy as np\n",
    "import IPython.display\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42604b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95cfc583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 15 09:04:29 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 527.56       Driver Version: 527.56       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   46C    P0    12W /  50W |      0MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11c58fa",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e17f387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767a87fa49754ed386a69cdd99fda96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1999 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(clean_sounds[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2000\u001b[39m]):\n\u001b[0;32m      6\u001b[0m     so,_ \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mdecode_wav(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_file(i),desired_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     clean_sounds_list \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat((clean_sounds_list,so),\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      9\u001b[0m noisy_sounds_list,_ \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mdecode_wav(tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_file(noisy_sounds[\u001b[38;5;241m0\u001b[39m]),desired_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(noisy_sounds[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2000\u001b[39m]):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clean_sounds = glob.glob('./CleanData/*')\n",
    "noisy_sounds = glob.glob('./NoisyData/*')\n",
    "\n",
    "clean_sounds_list,_ = tf.audio.decode_wav(tf.io.read_file(clean_sounds[0]),desired_channels=1)\n",
    "for i in tqdm(clean_sounds[1:2000]):\n",
    "    so,_ = tf.audio.decode_wav(tf.io.read_file(i),desired_channels=1)\n",
    "    clean_sounds_list = tf.concat((clean_sounds_list,so),0)\n",
    "\n",
    "noisy_sounds_list,_ = tf.audio.decode_wav(tf.io.read_file(noisy_sounds[0]),desired_channels=1)\n",
    "for i in tqdm(noisy_sounds[1:2000]):\n",
    "    so,_ = tf.audio.decode_wav(tf.io.read_file(i),desired_channels=1)\n",
    "    noisy_sounds_list = tf.concat((noisy_sounds_list,so),0)\n",
    "\n",
    "clean_sounds_list.shape,noisy_sounds_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d03e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample,_ = tf.audio.decode_wav(tf.io.read_file(\"./0021.wav\"),desired_channels=1)\n",
    "sample.shape\n",
    "\n",
    "# batching_size = 12000\n",
    "\n",
    "# sample_train = [],[]\n",
    "\n",
    "# for i in tqdm(range(0,clean_sounds_list.shape[0]-batching_size,batching_size)):\n",
    "#     sample_train.append(clean_sounds_list[i:i+batching_size])\n",
    "\n",
    "\n",
    "# clean_train = tf.stack(clean_train)\n",
    "\n",
    "\n",
    "# clean_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced8d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sounds_list.shape,noisy_sounds_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb92730",
   "metadata": {},
   "outputs": [],
   "source": [
    "batching_size = 12000\n",
    "\n",
    "clean_train,noisy_train = [],[]\n",
    "\n",
    "for i in tqdm(range(0,clean_sounds_list.shape[0]-batching_size,batching_size)):\n",
    "    clean_train.append(clean_sounds_list[i:i+batching_size])\n",
    "    noisy_train.append(noisy_sounds_list[i:i+batching_size])\n",
    "\n",
    "clean_train = tf.stack(clean_train)\n",
    "noisy_train = tf.stack(noisy_train)\n",
    "\n",
    "clean_train.shape,noisy_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded9820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb59758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train = []\n",
    "\n",
    "for j in tqdm(range(0,sample.shape[0]-batching_size,batching_size)):\n",
    "    sample_train.append(sample[j:j+batching_size])\n",
    "\n",
    "sample_train = tf.stack(sample_train)\n",
    "\n",
    "sample_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c789b40",
   "metadata": {},
   "source": [
    "# Create a tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b34d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(x_train,y_train):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "    dataset = dataset.shuffle(100).batch(64,drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e88840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(noisy_train[:40000],clean_train[:40000])\n",
    "test_dataset = get_dataset(noisy_train[40000:],clean_train[40000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b4eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdd8729",
   "metadata": {},
   "source": [
    "# Reviewing Sample Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb5ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveplot(np.squeeze(clean_train[5].numpy(),axis=-1))\n",
    "plt.show()\n",
    "librosa.display.waveplot(np.squeeze(noisy_train[5].numpy(),axis=-1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c452f2f",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4450632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(batching_size,1))\n",
    "c1 = Conv1D(2,32,2,'same',activation='relu')(inp)\n",
    "c2 = Conv1D(4,32,2,'same',activation='relu')(c1)\n",
    "c3 = Conv1D(8,32,2,'same',activation='relu')(c2)\n",
    "c4 = Conv1D(16,32,2,'same',activation='relu')(c3)\n",
    "c5 = Conv1D(32,32,2,'same',activation='relu')(c4)\n",
    "\n",
    "dc1 = Conv1DTranspose(32,32,1,padding='same')(c5)\n",
    "conc = Concatenate()([c5,dc1])\n",
    "dc2 = Conv1DTranspose(16,32,2,padding='same')(conc)\n",
    "conc = Concatenate()([c4,dc2])\n",
    "dc3 = Conv1DTranspose(8,32,2,padding='same')(conc)\n",
    "conc = Concatenate()([c3,dc3])\n",
    "dc4 = Conv1DTranspose(4,32,2,padding='same')(conc)\n",
    "conc = Concatenate()([c2,dc4])\n",
    "dc5 = Conv1DTranspose(2,32,2,padding='same')(conc)\n",
    "conc = Concatenate()([c1,dc5])\n",
    "dc6 = Conv1DTranspose(1,32,2,padding='same')(conc)\n",
    "conc = Concatenate()([inp,dc6])\n",
    "dc7 = Conv1DTranspose(1,32,1,padding='same',activation='linear')(conc)\n",
    "model = tf.keras.models.Model(inp,dc7)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4aeddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model,show_shapes=True,show_layer_names=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ba3cd8",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0656d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.002),loss=tf.keras.losses.MeanAbsoluteError())\n",
    "history = model.fit(train_dataset,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056ec29",
   "metadata": {},
   "source": [
    "# Testing Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3fad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(np.squeeze(noisy_train[22].numpy()),rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9fb2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(tf.squeeze(model.predict(tf.expand_dims(tf.expand_dims(noisy_train[22],-1),0))),rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b4a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ae97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('NoiseSuppressionModel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187732a8",
   "metadata": {},
   "source": [
    "# Inference\n",
    "## Handling different sized audio inputs can be solved by overlapping prediction frames and removing the intersection part from the final waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2826e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(path):\n",
    "    audio,_ = tf.audio.decode_wav(tf.io.read_file(path),1)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d3a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_preprocess(path):\n",
    "    audio = get_audio(path)\n",
    "    audio_len = audio.shape[0]\n",
    "    batches = []\n",
    "    for i in range(0,audio_len-batching_size,batching_size):\n",
    "        batches.append(audio[i:i+batching_size])\n",
    "\n",
    "    batches.append(audio[-batching_size:])\n",
    "    diff = audio_len - (i + batching_size)\n",
    "    return tf.stack(batches), diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0b83f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(path):\n",
    "    test_data,diff = inference_preprocess(path)\n",
    "    predictions = model.predict(test_data)\n",
    "    final_op = tf.reshape(predictions[:-1],((predictions.shape[0]-1)*predictions.shape[1],1))\n",
    "    final_op = tf.concat((final_op,predictions[-1][-diff:]),axis=0)\n",
    "    return final_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e0cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(np.squeeze(get_audio(noisy_sounds[4]).numpy(),-1),rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f70e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(np.squeeze(get_audio(\"./0003.wav\").numpy(),-1),rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d7e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(tf.squeeze(predict(noisy_sounds[4])),rate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(tf.squeeze(predict(\"./0003.wav\")),rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d6bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "tf.squeeze(predict(noisy_sounds[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eaf206",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveshow(np.squeeze(get_audio(noisy_sounds[4]).numpy(),-1))\n",
    "librosa.display.waveshow(np.squeeze(predict(noisy_sounds[4])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f4ba4f",
   "metadata": {},
   "source": [
    "# Quantization and TFLite Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06938bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lite_model = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "lite_model.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model_quant = lite_model.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a244f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TFLiteModel.tflite','wb') as f:\n",
    "    f.write(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b9af5",
   "metadata": {},
   "source": [
    "# TFLite Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ec018",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='./contents/TFLiteModel.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59967a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tflite(path):\n",
    "    test_audio,diff = inference_preprocess(path)\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    preds = []\n",
    "    for i in test_audio:\n",
    "        interpreter.set_tensor(input_index, tf.expand_dims(i,0))\n",
    "        interpreter.invoke()\n",
    "        predictions = interpreter.get_tensor(output_index)\n",
    "        preds.append(predictions)\n",
    "\n",
    "    predictions = tf.squeeze(tf.stack(preds,axis=1))\n",
    "    final_op = tf.reshape(predictions[:-1],((predictions.shape[0]-1)*predictions.shape[1],1))\n",
    "    final_op = tf.concat((tf.squeeze(final_op),predictions[-1][-diff:]),axis=0)\n",
    "    return final_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae7b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Noisy Audio\n",
    "Audio(np.squeeze(get_audio(noisy_sounds[4]).numpy(),-1),rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### sample파일을 바로 불러오기\n",
    "# get_audio(noisy_sounds[4]).numpy().shape\n",
    "# sample.shape\n",
    "# noisy_sounds[4].shape\n",
    "# noisy_sounds[4]\n",
    "Audio(np.squeeze(get_audio(\"./0003.wav\").numpy(),-1),rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c4821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Audio\n",
    "Audio(np.squeeze(get_audio(clean_sounds[4]).numpy(),-1),rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d681a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Audio\n",
    "Audio(predict_tflite(noisy_sounds[4]),rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4018a59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Output Audio sample\n",
    "Audio(predict_tflite(\"./0003.wav\"),rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a739cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "predict_tflite(noisy_sounds[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd196612",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.waveplot(np.squeeze(get_audio(noisy_sounds[4]).numpy(),-1))\n",
    "librosa.display.waveplot(predict_tflite(noisy_sounds[4]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30aec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "(get_audio(clean_sounds[4]).numpy(),-1)\n",
    "# Audio(np.squeeze(get_audio(clean_sounds[4]).numpy(),-1),rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab392f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sample.numpy(),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1d2d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59d73d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eab627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb5e3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352a70c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0274bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7c6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada5bb4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5174137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c40982d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbf159c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b337a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b0c125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f12c3c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300764b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25058718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ad0e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f457c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noise_kernel",
   "language": "python",
   "name": "noise"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
