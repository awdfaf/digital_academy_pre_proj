{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60d8e612",
   "metadata": {},
   "source": [
    "# tensorflow gpu사용 가능한지 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53652c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51b6229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.test.is_gpu_available()\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcb33841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b24f9f",
   "metadata": {},
   "source": [
    "# gpu 사용량 확인 + gpu 캐시 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa39656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 24 10:50:15 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 528.49       Driver Version: 528.49       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   45C    P0    11W /  50W |      0MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bf90b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7172f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4664191",
   "metadata": {},
   "source": [
    "# whisper 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "910db798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\envs\\noise\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (None)/charset_normalizer (3.1.0) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f10a8113",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f9c8ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 저는 차를 타고 가다가 실제로 고라니를 본 적이 있거든요. 새끼 고라니가 엄청 잘 뛰어 다니더라고요. 도로 위를 진짜 무법자처럼 막 뛰어 다녀요. 아니 근데 걔네는 법을 모르니까 무법자일 수밖에 없죠. 근데 새끼 고라니가 진짜 귀엽게 생기긴 했어요. 되게 귀엽더라고요. 걔네가 막 깡총깡총 뛰어 다니는데 집으로 데려가고 싶기도 했어요. 근데 걔네가 밤에는 정말 차에 돌진을 한다고 그러더라고요. 걔네가 진짜 위험하다고 그런 소리를 많이 들었어요. 아 그렇군요. 저는 살면서 고라니를 한 번도 본 적이 없는데 일단은 고라니 하면 떠오르는 게 고라니 울음소리 이런 게 떠오르는데 고라니가 막 의학하고 운다고 들었던 것 같거든요. 혹시 그러면 고라니가 어떻게 우는지 그것도 고라니 울음소리도 혹시 그때 실제로 들어보셨을까요? 저는 고라니 울음소리는 못 들었어요. 그때 걔네가 막 울면서 뛰어 다니진 않았고 그때 차 안에 있었는데 제가 몇 번을 보긴 했어요. 사실 새끼 고라니도 봤었고 고라니 시체도 본 적이 있고 다 큰 고라니도 옆에 막 뛰어 다니는 걸 보기도 했었고 고라니 때문에 사고가 날 뻔한 적도 있었어요. 근데 고라니 울음소리는 생각보다 듣기 쉬운 편은 아니더라고요. 걔네가 울면서 다니진 않나 봐요. 그러니까 자주 우는 편은 아닌가 봐요. 그 되게 자주 우는 사람들 있잖아요. 근데 고라니는 자주 우는 편은 아닌가 봐요. 걔네가 감성적인 타입은 아닌 것 같은 그런? 아 그렇군요. 근데 울면서 뛰어 다니지는 않는다고 했는데 그거를 들어보면서 생각을 해보니까 사람도 울면서 뛰어 다니지는 않잖아요. 아 물론 울면서 뛰는 이모티콘 이런 게 있기는 한데 근데 보통 같은 경우에는 울면서 몸을 움츠르고 있지 울면서 뛰어 다니지는 않거든요. 만약에 뛰면서 울고 있는 사람을 보면 모든 사람들이 그 사람을 쳐다보고 이목이 집중이 될 것 같은데 혹시 그러면 울면서 뛰어 다니는 사람을 보신 적이 있으신가요? 아니요. 저도 없는 것 같기는 해요. 그래서 생각해보니까 고라니가 울면서 뛰는 거를 보는 게 어려울 수도 있겠다는 생각이 갑자기 드네요. 저는 그 고라니가 귀엽게 생겼다고 했잖아요. 근데 진짜로 고라니를 실제로 보시면 귀엽다는 생각이 드실 거예요. 그리고 제가 그 시골에서 고라니를 본 거라서 우리나라에 고라니가 되게 많다고 그러잖아요. 근데 진짜로 많더라고요. 그렇군요. 근데 아까부터 계속 날개짓을 하고 계시던데 그거는 혹시 하늘로 날고 싶다는 뜻인가요? 아니면 뭔가 파닥파닥거리면서 파닥이 드시고 싶으신 건가요? 그 날개짓을 하고 계시는 그 날개짓의 의미를 제가 정말로 모르겠어서 진심으로 아까까지는 그냥 의무적으로 여쭤봤지만 지금은 진심으로 궁금해서 여쭤봅니다. 고라니 생각을 하다 보니까 갑자기 그냥 그 고라니들이 뛰어 다니는 게 생각이 나서 저도 모르게 이렇게 손을 파닥거린 거고요. 그 고라니들이 뛰어 다니는 게 생각이 났어요. 그랬는데 진짜 생각해보니까 갑자기 떠올랐는데 요즘에 킥보드 타고 다니는 사람들을 고라니랑 합쳐서 킹라니라고 부르더라고요. 들어보셨어요? 글쎄요. 저는 처음 들어보는데 일단은 고라니를 생각을 하면서 고라니들이 뛰어 다니는 모습을 그렇게 파닥파닥거리면서 표현을 하셨다고 하니까 고라니들이 그렇게 파닥대는 걸 보니까 파닥을 굉장히 좋아하나 봐요. 파닥 먹고 싶네요. 그게 킥보드 타는 사람들이 느닷없이 튀어나와서 그게 고라니랑 닮았다라는 그런 점에서 이제 킥라니라는 합성어가 나왔다고 해요. 근데 킥라니들이 너무 위험하니까 그런 말들이 나온 거긴 한데 킥보드 타는 분들이 잘못이라는 건 아니고 킥보드 타시는 분들이 이제 안전하게 헬멧도 잘 끼시고 그리고 안전하게 보호 용품인가요? 그거를 다 끼시고 안전하게 타셨으면 좋겠다라는 그런 말입니다. 아 네.\n"
     ]
    }
   ],
   "source": [
    "result = model.transcribe(\"./01_01_000606_210809_SD.wav\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c096521f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dde51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b876565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3673b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(\"news.wav\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    " \n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# decode the audio\n",
    "options = whisper.DecodingOptions()\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "\n",
    "    \n",
    "# print the recognized text\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e516cd7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09574c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12fd10e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noise_kernel",
   "language": "python",
   "name": "noise"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
